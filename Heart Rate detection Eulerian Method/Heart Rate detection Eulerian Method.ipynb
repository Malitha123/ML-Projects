{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05921722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.fftpack as fftpack\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d638de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_min = 1 # range for Fast-Fourier Transform\n",
    "freq_max = 1.8\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascades/haarcascade_frontalface_alt0.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76dcec5",
   "metadata": {},
   "source": [
    "# Support function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94a81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_video_pyramid(frames):\n",
    "    lap_video = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        pyramid = generate_laplacian_pyramid(frame, 3)\n",
    "        for j in range(3):\n",
    "            if i == 0:\n",
    "                lap_video.append(np.zeros((len(frames), pyramid[j].shape[0], pyramid[j].shape[1], 3)))\n",
    "            lap_video[j][i] = pyramid[j]\n",
    "\n",
    "    return lap_video\n",
    "\n",
    "\n",
    "\n",
    "def generate_laplacian_pyramid(img, levels):\n",
    "    gaussian_pyramid = generate_gaussian_pyramid(img, levels)\n",
    "    laplacian_pyramid = []\n",
    "\n",
    "    for i in range(levels-1):\n",
    "        upsampled = cv2.pyrUp(gaussian_pyramid[i+1])\n",
    "        (height, width, depth) = upsampled.shape\n",
    "        gaussian_pyramid[i] = cv2.resize(gaussian_pyramid[i], (height, width))\n",
    "        diff = cv2.subtract(gaussian_pyramid[i],upsampled)\n",
    "        laplacian_pyramid.append(diff)\n",
    "\n",
    "    laplacian_pyramid.append(gaussian_pyramid[-1])\n",
    "\n",
    "    return laplacian_pyramid\n",
    "\n",
    "\n",
    "def generate_gaussian_pyramid(img, levels):\n",
    "    float_img = np.ndarray(shape=img.shape, dtype=\"float\")\n",
    "    float_img[:] = img\n",
    "    pyramid = [float_img]\n",
    "\n",
    "    for i in range(levels-1):\n",
    "        float_img = cv2.pyrDown(float_img)\n",
    "        pyramid.append(float_img)\n",
    "\n",
    "    return pyramid\n",
    "\n",
    "\n",
    "def collapse_laplacian_pyramid(video, frame_ct):\n",
    "    collapsed_video = []\n",
    "\n",
    "    for i in range(frame_ct):\n",
    "        prev_frame = video[-1][i]\n",
    "\n",
    "        for level in range(len(video) - 1, 0, -1):\n",
    "            pyr_up_frame = cv2.pyrUp(prev_frame)\n",
    "            (height, width, depth) = pyr_up_frame.shape\n",
    "            prev_level_frame = video[level - 1][i]\n",
    "            prev_level_frame = cv2.resize(prev_level_frame, (height, width))\n",
    "            prev_frame = pyr_up_frame + prev_level_frame\n",
    "\n",
    "        # Normalize pixel values\n",
    "        min_val = min(0.0, prev_frame.min())\n",
    "        prev_frame = prev_frame + min_val\n",
    "        max_val = max(1.0, prev_frame.max())\n",
    "        prev_frame = prev_frame / max_val\n",
    "        prev_frame = prev_frame * 255\n",
    "\n",
    "        prev_frame = cv2.convertScaleAbs(prev_frame)\n",
    "        collapsed_video.append(prev_frame)\n",
    "\n",
    "    return collapsed_video\n",
    "\n",
    "def fft_filter(video, freq_min, freq_max, fps):\n",
    "    fft = fftpack.fft(video, axis=0)\n",
    "    frequencies = fftpack.fftfreq(video.shape[0], d=1.0 / fps)\n",
    "    bound_low = (np.abs(frequencies - freq_min)).argmin()\n",
    "    bound_high = (np.abs(frequencies - freq_max)).argmin()\n",
    "    fft[:bound_low] = 0\n",
    "    fft[bound_high:-bound_high] = 0\n",
    "    fft[-bound_low:] = 0\n",
    "    iff = fftpack.ifft(fft, axis=0)\n",
    "    result = np.abs(iff)\n",
    "    result *= 100  # Amplification factor\n",
    "\n",
    "    return result, fft, frequencies\n",
    "\n",
    "def read_video(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    video_frames = []\n",
    "    face_rects = ()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        roi_frame = img\n",
    "\n",
    "        # Detect face\n",
    "        if len(video_frames) == 0:\n",
    "            face_rects = faceCascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # Select ROI\n",
    "        if len(face_rects) > 0:\n",
    "            for (x, y, w, h) in face_rects:\n",
    "                roi_frame = img[y:y + h, x:x + w]\n",
    "            if roi_frame.size != img.size:\n",
    "                roi_frame = cv2.resize(roi_frame, (500, 500))\n",
    "                frame = np.ndarray(shape=roi_frame.shape, dtype=\"float\")\n",
    "                frame[:] = roi_frame * (1. / 255)\n",
    "                video_frames.append(frame)\n",
    "\n",
    "    frame_ct = len(video_frames)\n",
    "    cap.release()\n",
    "\n",
    "    return video_frames, frame_ct, fps\n",
    "\n",
    "def find_heart_rate(fft, freqs, freq_min, freq_max):\n",
    "    fft_maximums = []\n",
    "\n",
    "    for i in range(fft.shape[0]):\n",
    "        if freq_min <= freqs[i] <= freq_max:\n",
    "            fftMap = abs(fft[i])\n",
    "            fft_maximums.append(fftMap.max())\n",
    "        else:\n",
    "            fft_maximums.append(0)\n",
    "\n",
    "    peaks, properties = signal.find_peaks(fft_maximums)\n",
    "    max_peak = -1\n",
    "    max_freq = 0\n",
    "\n",
    "    # Find frequency with max amplitude in peaks\n",
    "    for peak in peaks:\n",
    "        if fft_maximums[peak] > max_freq:\n",
    "            max_freq = fft_maximums[peak]\n",
    "            max_peak = peak\n",
    "\n",
    "    return freqs[max_peak] * 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191bd93",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e88fc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budiling video pyramid\n",
      "calculating fft\n",
      "Calculating heart rate...\n",
      "Heart rate:  65.78073089700997 bpm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "video_frames, frame_ct, fps = read_video(\"./data/face.mp4\")\n",
    "\n",
    "print(\"budiling video pyramid\")\n",
    "lap_video = build_video_pyramid(video_frames)\n",
    "\n",
    "amplified_video_pyramid = []\n",
    "\n",
    "for i, video in enumerate(lap_video):\n",
    "    if i == 0 or i == len(lap_video)-1:\n",
    "        continue\n",
    "    print(\"calculating fft\")\n",
    "    result, fft, frequencies = fft_filter(video, freq_min, freq_max, fps)\n",
    "    lap_video[i] += result\n",
    "\n",
    "    # Calculate heart rate\n",
    "    print(\"Calculating heart rate...\")\n",
    "    heart_rate = find_heart_rate(fft, frequencies, freq_min, freq_max)\n",
    "print(\"Heart rate: \", heart_rate, \"bpm\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
